{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solobala/RMSL_9/blob/main/NLP_classification_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLMwKINn0vqi"
      },
      "source": [
        "3 раза разными способами получить на задаче классификации значение f1 выше 0.91 для методов на sklearn и выше 0.52 для методов на pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSm0ju9puyiP"
      },
      "source": [
        "Предварительно про PyTorch:\n",
        "* [Про тензоры в pytorch](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/tensor_tutorial.ipynb)\n",
        "* [Про автоматическое дифференцирование и что такое .backwards()](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/autograd_tutorial.ipynb)\n",
        "* [Очень простая нейронка на pytorch](https://colab.research.google.com/drive/1RsZvw4KBGn5U5Aj5Ak7OG2pHx6z1OSlF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgMmb-QuyiT"
      },
      "source": [
        "# Классификация текстов\n",
        "\n",
        "## Fakenews\n",
        "\n",
        "1. Мы будем работать с данными fakenews отсюда: https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\n",
        "2. Проведите препроцессинг текста. Разбейте данные на train и test для задачи классификации.\n",
        "3. Векторизуйте.\n",
        "4. Обучите на полученных векторах алгоритм классификации.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h5dqdfX0vqk"
      },
      "source": [
        "word2vec official tutorial: https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
        "https://github.com/RaRe-Technologies/gensim-data#models - здесь можно скачать предобученные модели\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcZStwdh0vqk"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EQ4-xO7uyiU",
        "outputId": "ac69cb64-cdf7-48de-bee3-816ed76d5423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-06 16:39:03--  https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1253562 (1.2M) [text/plain]\n",
            "Saving to: ‘Constraint_Train.csv’\n",
            "\n",
            "Constraint_Train.cs 100%[===================>]   1.20M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-09-06 16:39:04 (29.0 MB/s) - ‘Constraint_Train.csv’ saved [1253562/1253562]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YCpo8FuuyiW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "TEST_SPLIT_SIZE = 0.33"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NSv9Mo9X-tT",
        "outputId": "c2feec77-03b5-4e0e-8156-bf0c32c632f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# df = pd.read_csv('Constraint_Train.csv')\n",
        "try:\n",
        "    import google.colab\n",
        "    df = pd.read_csv('/content/Constraint_Train.csv')\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    COLAB = True\n",
        "except:\n",
        "    from beholder import print_methods\n",
        "    df = pd.read_csv(\"/Users/velo1/SynologyDrive/GIT_syno/data/NLP/Constraint_Train.csv\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hgpfPhA0uyiX",
        "outputId": "23b835f9-3659-4564-9375-d4f6b056fb7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9de67691-de92-49df-bbbb-c244b3cbfbe7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9de67691-de92-49df-bbbb-c244b3cbfbe7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9de67691-de92-49df-bbbb-c244b3cbfbe7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9de67691-de92-49df-bbbb-c244b3cbfbe7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68781b4a-36bb-4454-9d0f-3686c30c1f60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68781b4a-36bb-4454-9d0f-3686c30c1f60')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68781b4a-36bb-4454-9d0f-3686c30c1f60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwMAW01b0vqm"
      },
      "source": [
        "## ```Naive``` (sklearn vectorizer) methods for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QVUEiLfuyiY"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from string import punctuation\n",
        "\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iq-byaJ0vqn"
      },
      "source": [
        "### ``word2vec``\n",
        "A. vectorizing with word2vec based on fakenews corpora  \n",
        "\n",
        "B. vectorizing with word2vec based on pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d11MOaSK0vqn"
      },
      "source": [
        "### Tokenization of tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f-LcwMqC0vqn",
        "outputId": "1c4dc5bb-a64f-422a-b75b-c3dfe2ac0d40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO62Fv2YuyiY",
        "outputId": "58033af2-6472-45a5-9ae4-6255e463b191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.\n",
            "['the', 'cdc', 'currently', 'reports', '99031', 'deaths.', 'in', 'general', 'the', 'discrepancies', 'in', 'death', 'counts', 'between', 'different', 'sources', 'are', 'small', 'and', 'explicable.', 'the', 'death', 'toll', 'stands', 'at', 'roughly', '100000', 'people', 'today', '.']\n"
          ]
        }
      ],
      "source": [
        "# tokenize the sentences using nltk.tokenize.word_tokenize\n",
        "sentences = [\n",
        "    TreebankWordTokenizer().tokenize(text=text.lower())\n",
        "    for text in df.tweet\n",
        "    if text not in punctuation\n",
        "]\n",
        "print(df.loc[0, \"tweet\"])\n",
        "print(sentences[0])  # first sentence token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRAxM00J0vqn",
        "outputId": "4c452d5a-1960-4848-9e8b-7a3d987b7a6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(29, 30)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.loc[0, \"tweet\"].split()), len(sentences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd40uuLR0vqo"
      },
      "source": [
        "### Vectorization of tweets with word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV6DsOOPuyiZ",
        "outputId": "7d50b541-11dd-4f6b-e925-34843f60ec84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5534\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "# train the word2vec model on the corpus\n",
        "model_tweets = Word2Vec(\n",
        "    sentences, workers=4, vector_size=300, min_count=3, window=7, epochs=15\n",
        ")\n",
        "print(\n",
        "    len(model_tweets.wv.key_to_index)\n",
        ")  # print out the number of unique words in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONvlrKsl0vqo",
        "outputId": "f55b1ffa-d0f7-49a6-d3c8-dc7a0255345a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['add_lifecycle_event', 'add_vector', 'add_vectors', 'allocate_vecattrs', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_analogies', 'evaluate_word_pairs', 'expandos', 'fill_norms', 'get_index', 'get_mean_vector', 'get_normed_vectors', 'get_vecattr', 'get_vector', 'has_index_for', 'index2entity', 'index2word', 'index_to_key', 'init_sims', 'intersect_word2vec_format', 'key_to_index', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'mapfile_path', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'next_index', 'norms', 'rank', 'rank_by_centrality', 'relative_cosine_similarity', 'resize_vectors', 'save', 'save_word2vec_format', 'set_vecattr', 'similar_by_key', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_unseen_docs', 'sort_by_descending_frequency', 'unit_normalize_all', 'vector_size', 'vectors', 'vectors_for_all', 'vectors_lockf', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than']\n"
          ]
        }
      ],
      "source": [
        "# print out the often used methods of the w2v model\n",
        "print([meth for meth in dir(model_tweets.wv) if not meth.startswith(\"_\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xruscvxB0vqo"
      },
      "outputs": [],
      "source": [
        "def check_similarity(model, word) -> list:\n",
        "    \"\"\"Check the similarity of the word with the words in the vocabulary\n",
        "    Args:\n",
        "        model: gensim.models.word2vec.Word2Vec\n",
        "        word: str\n",
        "    Returns:\n",
        "        list of tuples (word, similarity)\n",
        "    \"\"\"\n",
        "    if hasattr(model, \"wv\"):\n",
        "        try:\n",
        "            return model.wv.most_similar(word)\n",
        "        except KeyError:\n",
        "            print(f\"Word {word} is not in a vocabulary\")\n",
        "            return list()\n",
        "    else:\n",
        "        try:\n",
        "            return model.most_similar(word)\n",
        "        except KeyError:\n",
        "            print(f\"Word {word} is not in a vocabulary\")\n",
        "            return list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL0SlQ6v0vqo",
        "outputId": "34703306-3778-4118-b90a-c03a8fb2091e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('corona', 0.6087474822998047),\n",
              " ('done.', 0.5820356607437134),\n",
              " ('coronavirus', 0.5296990871429443),\n",
              " ('u', 0.5094467401504517),\n",
              " ('liquid', 0.49752095341682434),\n",
              " ('moderna', 0.48310214281082153),\n",
              " ('deadly', 0.48059484362602234),\n",
              " (',', 0.47637826204299927),\n",
              " ('covid.', 0.47364217042922974),\n",
              " ('bacteria', 0.47092533111572266)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_similarity(model_tweets, \"covid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PPszKE_Q0vqp"
      },
      "outputs": [],
      "source": [
        "# print_methods(model_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmqe5t6BuyiZ",
        "outputId": "c4eb4257-70d5-49a6-e91c-a92004397aee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('cure', 0.7838325500488281),\n",
              " ('drug', 0.7821235656738281),\n",
              " ('developed', 0.774448037147522),\n",
              " ('scientists', 0.7422436475753784),\n",
              " ('company', 0.7421199083328247),\n",
              " ('fight', 0.7396377921104431),\n",
              " ('remedy', 0.7350128889083862),\n",
              " ('eradicate', 0.7237803936004639),\n",
              " ('against', 0.7186787128448486),\n",
              " ('created', 0.7168167233467102)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_tweets.wv.most_similar(\"vaccine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H1C2ivBwuyia"
      },
      "outputs": [],
      "source": [
        "# model_tweets.init_sims() # Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9aQM-6_Cuyib"
      },
      "outputs": [],
      "source": [
        "def get_aggregated_embedding(tweet: list, model, dimension=300) -> np.array:\n",
        "    \"\"\"Retrieve aggregated (summing) embedding of a text.\n",
        "    Args:\n",
        "        tweet (list): A list of words.\n",
        "        model: gensim.models.word2vec.Word2Vec\n",
        "        dimension (int): The dimension of the word embedding.\n",
        "    Returns:\n",
        "        np.array: A vector of size 'dimension' containing the aggregated text embedding.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for word in tweet:\n",
        "        # check if model has method wv (word2vec) or not (glove)\n",
        "        if hasattr(model, \"wv\"):\n",
        "            # check if word is in vocabulary\n",
        "            if word in model.wv:\n",
        "                result.append(model.wv[word])\n",
        "            else:\n",
        "                result.append(np.zeros(dimension))\n",
        "        else:\n",
        "            # check if word is in vocabulary\n",
        "            if word in model:\n",
        "                result.append(model[word])\n",
        "            else:\n",
        "                result.append(np.zeros(dimension))\n",
        "\n",
        "    if len(result):\n",
        "        result = np.sum(\n",
        "            result, axis=0\n",
        "        )  # sum of word embeddings in one tweet (aggregation)\n",
        "    else:\n",
        "        result = np.zeros(dimension)  # zero vector if no words found in model\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MEXHIkb7uyib"
      },
      "outputs": [],
      "source": [
        "features = [\n",
        "    get_aggregated_embedding(tweet=tweet, model=model_tweets, dimension=300)\n",
        "    for tweet in sentences\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa5wOyB10vqp",
        "outputId": "9a46dff4-ae09-49cb-f2ab-53e78d68aea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features[0].shape  # 300 is the dimension of the word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucQ4_h850vqq",
        "outputId": "fa3c74c2-b2d2-42b4-8ac0-4b759b61cbad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of zero vectors: 0 in features\n"
          ]
        }
      ],
      "source": [
        "# Check for presence of zero vectors in features (if no words found in model)\n",
        "num_zero_vectors = np.sum(np.all(features == 0, axis=0))\n",
        "print(f\"Number of zero vectors: {num_zero_vectors} in features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDrzK7k70vqq"
      },
      "source": [
        "### Classification with LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KYWbsK2Duyic"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "45OhRwtTuyic",
        "outputId": "6b28ea62-08f7-4c0b-d3de-de492312e04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 6420, shape of each feature: (300,)\n"
          ]
        }
      ],
      "source": [
        "# features hear is a list of vectors of size 300 (aggregated word embeddings) for each tweet\n",
        "print(\n",
        "    f\"Number of features: {len(features)}, shape of each feature: {features[0].shape}\"\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, df.label, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_JNAMZ2uyic",
        "outputId": "7ad25e90-c234-484f-98dc-c8389dfd02af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.923     0.912     0.918      1004\n",
            "        real      0.922     0.932     0.927      1115\n",
            "\n",
            "    accuracy                          0.923      2119\n",
            "   macro avg      0.923     0.922     0.922      2119\n",
            "weighted avg      0.923     0.923     0.923      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_lr = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        ")\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "predicted = model_lr.predict(X_test)\n",
        "print(classification_report(y_test, predicted, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XAQuN4Jxsq2"
      },
      "source": [
        "### Classification with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9szH095xsq2",
        "outputId": "77a17858-dfb2-4032-a8a8-89935b82a3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5534\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.946     0.919     0.932      1004\n",
            "        real      0.929     0.952     0.941      1115\n",
            "\n",
            "    accuracy                          0.937      2119\n",
            "   macro avg      0.937     0.936     0.936      2119\n",
            "weighted avg      0.937     0.937     0.937      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# simple tokenizer\n",
        "text_rfc = [TreebankWordTokenizer().tokenize(text=text.lower()) for text in df.tweet]\n",
        "\n",
        "# train the word2vec model on the corpus\n",
        "model_tweets_rfc = Word2Vec(\n",
        "    text_rfc, workers=4, vector_size=300, min_count=3, window=31, epochs=15\n",
        ")\n",
        "\n",
        "# vectorization\n",
        "features_rfc = [\n",
        "    get_aggregated_embedding(tweet=tweet, model=model_tweets_rfc, dimension=300)\n",
        "    for tweet in text_rfc\n",
        "]\n",
        "\n",
        "print(\n",
        "    len(model_tweets_rfc.wv.key_to_index)\n",
        ")  # print out the number of unique words in the vocabulary\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_rfc, df.label, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        ")\n",
        "\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=100, random_state=42, n_jobs=-1, verbose=0)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "predicted = model_rf.predict(X_test)\n",
        "print(classification_report(y_test, predicted, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M40rZB40vqq"
      },
      "source": [
        "## let's use `pre-trained` models for vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nkHzc7yC0vqr"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors  # for loading word2vec model from file\n",
        "\n",
        "\n",
        "# download pretrained word2vec model from gensim-data\n",
        "# print(api.load(\"glove-wiki-gigaword-300\", return_path=True))  # output: /home/user/gensim-data/glove-twitter-25/glove-twitter-25.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngqqWdX50vqr"
      },
      "source": [
        "### The same steps as above but with pre-trained model:\n",
        "1. Download pre-trained model from local file\n",
        "2. Vectorize tweets with pre-trained model\n",
        "3. Classification with LogisticRegression\n",
        "4. Print classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IUzRJIbn0vqr",
        "outputId": "25b8eec4-34e0-4dcd-91d9-b1cd8b29b7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "Word covid is not in a vocabulary\n",
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n",
            "Word covid is not in a vocabulary\n",
            "[=================================================-] 99.6% 374.4/376.1MB downloaded\n",
            "Word covid is not in a vocabulary\n"
          ]
        }
      ],
      "source": [
        "models = [\"glove-twitter-25\", \"glove-twitter-50\", \"glove-wiki-gigaword-300\"]\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    if COLAB:\n",
        "        pretr_model = api.load(model_name)\n",
        "\n",
        "    else:\n",
        "        # construct local path to the model\n",
        "        path = \"/Users/velo1/gensim-data/\" + model_name + \"/\" + model_name + \".gz\"\n",
        "        pretr_model = KeyedVectors.load_word2vec_format(path, binary=False)\n",
        "        msg = f\"Loaded model {model_name}\"\n",
        "        print(msg)\n",
        "        os.system(f\"Say {msg}\")\n",
        "\n",
        "    dimension = pretr_model.vector_size\n",
        "    vocab_size = len(pretr_model.key_to_index)\n",
        "    # define features (embeddings) for each tweet\n",
        "    features2 = [\n",
        "        get_aggregated_embedding(tweet=tweet, model=pretr_model, dimension=dimension)\n",
        "        for tweet in sentences\n",
        "    ]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features2, df.label, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        "    )\n",
        "    # train logistic regression model\n",
        "    model_lr = LogisticRegression(max_iter=2000, random_state=42)\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    predicted = model_lr.predict(X_test)\n",
        "\n",
        "    check_similarity(pretr_model, \"covid\")\n",
        "    results[model_name] = [\n",
        "        classification_report(y_test, predicted, output_dict=True, digits=3)[\"macro avg\"][\"f1-score\"],\n",
        "        vocab_size,\n",
        "        dimension,\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ks8Y5k0vqr"
      },
      "source": [
        "Some takeaways on ``pre-tained models`` for word2vec:  \n",
        "\n",
        "The Glove model is trained on the non-contextualized word vectors.  \n",
        "It is trained on the aggregated global word-word co-occurrence statistics from a corpus,  \n",
        "and the resulting representations showcase interesting linear substructures of the word vector space.  \n",
        "The Glove model is trained on the Wikipedia 2014 + Gigaword 5 dataset,  \n",
        "which contains 6 billion tokens and 400 thousand vocabularies.  \n",
        "The dimension of the word vector is 300.  \n",
        "\n",
        "But the fact it was published in 2014 makes it a bit outdated.  \n",
        "So `covid` is not in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_mwsaXL0vqr"
      },
      "source": [
        "### The results summary of classification with pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9CycBvp30vqr",
        "outputId": "2b30a53a-9507-4d14-b26f-5d2c71da6abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model glove-twitter-25              : macro avg f1-score 0.835, vocab size 1193514, dimension 25\n",
            "Model glove-twitter-50              : macro avg f1-score 0.854, vocab size 1193514, dimension 50\n",
            "Model glove-wiki-gigaword-300       : macro avg f1-score 0.903, vocab size 400000, dimension 300\n"
          ]
        }
      ],
      "source": [
        "for key, value in results.items():\n",
        "    print(\n",
        "        f\"Model {key:<30}: macro avg f1-score {value[0]:.3f}, vocab size {value[1]}, dimension {value[2]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EERFQtj20vqs"
      },
      "source": [
        "#### The more is the dimension of the vector, the better is the result of classification (f1-score)\n",
        "#### despite the lower number of words in the vocabulary (three times less)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6RUCxFWk0vqs",
        "outputId": "027ec461-c287-4f3b-b5ea-494adeed5c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compare the most similar words from pretrained Glove model\n",
            "and model trained on tweets  for the word 'vaccine':\n",
            "\n",
            "Pretrained Glove Model                Model from Tweets\n",
            "------------------------------------  ----------------------------------\n",
            "('vaccines', 0.849010169506073)       ('cure', 0.7838325500488281)\n",
            "('flu', 0.6364811062812805)           ('drug', 0.7821235656738281)\n",
            "('vaccination', 0.6324456334114075)   ('developed', 0.774448037147522)\n",
            "('doses', 0.6266157031059265)         ('scientists', 0.7422436475753784)\n",
            "('influenza', 0.6076477766036987)     ('company', 0.7421199083328247)\n",
            "('smallpox', 0.6020570993423462)      ('fight', 0.7396377921104431)\n",
            "('polio', 0.587674617767334)          ('remedy', 0.7350128889083862)\n",
            "('vaccinations', 0.5871402025222778)  ('eradicate', 0.7237803936004639)\n",
            "('virus', 0.5832216143608093)         ('against', 0.7186787128448486)\n",
            "('measles', 0.5729112029075623)       ('created', 0.7168167233467102)\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "data = list(\n",
        "    zip(pretr_model.most_similar(\"vaccine\"), model_tweets.wv.most_similar(\"vaccine\"))\n",
        ")\n",
        "\n",
        "# Print the table\n",
        "print(\n",
        "    \"Compare the most similar words from pretrained Glove model\\n\"\n",
        "    \"and model trained on tweets  for the word 'vaccine':\\n\"\n",
        ")\n",
        "print(tabulate(data, headers=[\"Pretrained Glove Model\", \"Model from Tweets\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vjBHuTF0vqs"
      },
      "source": [
        "Pretrained model with vectors of dimension 300 performs vectorisation as good as  \n",
        "custom models trained on fakenews corpora with vectors of dimension 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qCQpNduyid"
      },
      "source": [
        "###  Let's try to use one more ```counting vectorizer```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKLUWP8huyie",
        "outputId": "832e0324-01e8-456d-e0a0-ac1c00393f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 18385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.914     0.926     0.920      1004\n",
            "        real      0.933     0.921     0.927      1115\n",
            "\n",
            "    accuracy                          0.924      2119\n",
            "   macro avg      0.923     0.924     0.923      2119\n",
            "weighted avg      0.924     0.924     0.924      2119\n",
            "\n",
            "Vocabulary size: 25796\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.786     0.853     0.818      1004\n",
            "        real      0.856     0.791     0.822      1115\n",
            "\n",
            "    accuracy                          0.820      2119\n",
            "   macro avg      0.821     0.822     0.820      2119\n",
            "weighted avg      0.823     0.820     0.820      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "for data in [df.tweet, [\"\".join(word) for word in sentences]]:\n",
        "    # print(f'Using data: {data}')\n",
        "    vec = CountVectorizer()  # simple count vectorizer\n",
        "    bow = vec.fit_transform(data)  # document-term matrix (bag of words)\n",
        "    print(f\"Vocabulary size: {len(vec.vocabulary_)}\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        bow, df.label, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    model = LogisticRegression(max_iter=2000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    predicted = model.predict(X_test)\n",
        "    print(classification_report(y_test, predicted, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndIbmL7Y0vqs"
      },
      "source": [
        "Despite of greater vocabulary size CountVectorizer based on TreebankTokenizer   \n",
        "performs worse than\n",
        "CountVectorizer based on raw text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKke_hOo0vqt"
      },
      "source": [
        "### Let's try tf-idf vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAUroHeO0vqt",
        "outputId": "676cda40-7ac9-4d25-b87c-1f7dabd44654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.889     0.941     0.914      1004\n",
            "        real      0.944     0.894     0.918      1115\n",
            "\n",
            "    accuracy                          0.916      2119\n",
            "   macro avg      0.917     0.918     0.916      2119\n",
            "weighted avg      0.918     0.916     0.917      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import tf-idf vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# define vectorizer\n",
        "vec = TfidfVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 2))\n",
        "# vec = TfidfVectorizer(lowercase=False,  ngram_range=(1, 1))\n",
        "# fit vectorizer on data\n",
        "tfidf = vec.fit_transform(df.tweet)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    tfidf, df.label, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        ")\n",
        "model = LogisticRegression(max_iter=2000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "print(classification_report(y_test, predicted, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df3Pa4ai0vqt"
      },
      "source": [
        "With tfidf vectorizer based on raw text (unigrams without lowercasing) we get the results of classification  \n",
        "slioghtly better than on bigrams with lowercasing.  \n",
        "Interesting fact so far.  \n",
        "Maybe some punctuation marks are important for classification!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBnGIg1t0vqt"
      },
      "source": [
        "## RNN for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6qOclJPuyif"
      },
      "source": [
        "### PyTorch + LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4geaVXik0vqt"
      },
      "source": [
        "We need to transform labels (fake / real ) to numbers (0 / 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHDxqZnTuyif",
        "outputId": "5c3c8320-da1b-4d2c-fe24-9053b0e9facf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1, 1, 0, 1, 1, 1, 1, 0, 0, 0], 6420)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = (df.label == \"real\").astype(int).to_list()  # 1 for real, 0 for fake\n",
        "labels[:10], len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fUz2OKauyif"
      },
      "source": [
        "#### Limit the number of words in one tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BkQTxbMuyig",
        "outputId": "7d67af68-043e-4118-d9cd-1a719ab91757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The max number of tokens (words) in one tweet: 8846\n",
            "The number of words in the longest tweet: 1456\n",
            "Index of the longest tweet: 270\n"
          ]
        }
      ],
      "source": [
        "max_len = len(max(df.tweet, key=len))  # max length of tokenized tweet\n",
        "\n",
        "# find index of token with max length in sentences (list of tokenized tweets)\n",
        "# max_index = sentences.index(\n",
        "#     max(sentences, key=len)\n",
        "# )  # index of longest tweet in token_lists\n",
        "\n",
        "max_len = len(max(df.tweet, key=len))  # max length of tokenized tweet\n",
        "\n",
        "# find index of token with max length in df.tweet\n",
        "max_index = df.tweet.apply(len).idxmax()  # index of longest tweet in token_lists\n",
        "\n",
        "print(\n",
        "    f\"The max number of tokens (words) in one tweet: {max_len}\"\n",
        ")  # max length of tokenized tweet (number of tokens (words) in longest tweet)\n",
        "print(\n",
        "    f'The number of words in the longest tweet: {len(df.loc[max_index, \"tweet\"].split())}'\n",
        ")  # number of words in longest tweet\n",
        "# find index of token with max length\n",
        "\n",
        "print(f\"Index of the longest tweet: {max_index}\")\n",
        "# print(f'\\nThe longest tweet:\\n{df.loc[max_index, \"tweet\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUNPzqWuyig"
      },
      "source": [
        "1456 words in one tweet is too much for LSTM\n",
        "\n",
        "What is the frequency distribution of the number of words in tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TQVd6Fruyig",
        "outputId": "4b757442-e861-4c6b-acff-70de0ace482e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    from collections import Counter\n",
        "except:\n",
        "    !python -m pip install collections\n",
        "    from collections import Counter\n",
        "\n",
        "fd = Counter(\n",
        "    [len(word_tokenize(tokens)) for tokens in df.tweet]\n",
        ")  # frequency distribution of tweet lengths\n",
        "len(fd.values())  # number of unique tweet lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Ylc_ua0vqu",
        "outputId": "360b836c-c8da-4fe1-e7ae-d569b42c48e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(20, 177),\n",
              " (25, 174),\n",
              " (22, 170),\n",
              " (18, 170),\n",
              " (19, 168),\n",
              " (21, 168),\n",
              " (17, 164),\n",
              " (15, 161),\n",
              " (16, 161),\n",
              " (23, 156)]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fd.most_common(10)  # 10 most common tweet lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FgPQHvno0vqu",
        "outputId": "ddf386df-0964-4e6f-b871-5c1aa0be222a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fd.most_common(10)   # 10 most common tweet lengths in tokens\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(list(fd.keys()), list(fd.values()), color=\"g\")\n",
        "plt.xlim(0, 200)\n",
        "plt.title(\"Frequency distribution of tweet lengths (in words)\")\n",
        "plt.xlabel(\"Number of words(tokens) in a tweet\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LNWZldVuyih"
      },
      "source": [
        "Зададим максимум 200 слов в 1 твите."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxPTNDQ0uyii"
      },
      "source": [
        "Возьмём те же w2v эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNOPWCq1uyii",
        "outputId": "fbde61df-0b77-4965-f991-0e065e8ca6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words in the first tweet: 30, embedding shape: (200, 300)\n"
          ]
        }
      ],
      "source": [
        "def get_word_embedding(tokens: list, max_words=200) -> np.array:\n",
        "    \"\"\"Retrieve the word embedding of a list of tokens limited by max_len of words.\n",
        "    Args:\n",
        "        tokens (list): A list of tokens.\n",
        "        max_words (int): The maximum length of the list of tokens.\n",
        "    Returns:\n",
        "        np.array: A matrix of size (max_words, 300) containing the word embeddings.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for i in range(max_words):  # iterate through the indices (limited by max_len)\n",
        "        if i < len(\n",
        "            tokens\n",
        "        ):  # get the embedding of the word if the index is less than the length of the tweet\n",
        "            word = tokens[i]\n",
        "            if word in model_tweets.wv:\n",
        "                result.append(\n",
        "                    model_tweets.wv[word]\n",
        "                )  # append the word embedding to the result\n",
        "            else:\n",
        "                result.append(\n",
        "                    np.zeros(300)\n",
        "                )  # zero vector if word not found in model, 300 is the embedding size\n",
        "        else:  # if index is greater than the length of the tweet\n",
        "            result.append(\n",
        "                np.zeros(300)\n",
        "            )  # pad with zero vectors if index is greater than the length of the tweet\n",
        "    return result\n",
        "\n",
        "\n",
        "emb = get_word_embedding(sentences[0], max_words=200)  # first tweet, first 10 words\n",
        "print(\n",
        "    f\"Number of words in the first tweet: {len(sentences[0])}, embedding shape: {np.array(emb).shape}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVxacsIa0vqv",
        "outputId": "9f1ef4be-7c7e-4973-fc74-1436f7022b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6420, 200, 300)\n"
          ]
        }
      ],
      "source": [
        "# token_lists - list of lists (tokenized tweets)\n",
        "features_2d = [get_word_embedding(text, max_words=200) for text in sentences]\n",
        "print(np.array(features_2d).shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_2d, labels, test_size=TEST_SPLIT_SIZE, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXHLD6eKuyij",
        "outputId": "ea74d006-b12a-46cb-d875-d666e0e5155f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn  # neural network module\n",
        "import torch.optim as optim  # optimization module\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNRDEXNRdOF",
        "outputId": "99f765fd-6f07-4fd3-a3a6-d8f6a6a6a145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4301"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)  # the number of training samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUp02qCM0vqw"
      },
      "source": [
        "## [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYq2Ggh80vqw",
        "outputId": "a604d902-178e-44e9-9956-86e4dab8c87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTMClassifier(\n",
            "  (lstm): LSTM(300, 200, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_dim,\n",
        "        seq_len,\n",
        "        output_size,\n",
        "        n_layers=2,\n",
        "        drop_prob=0.2,\n",
        "    ):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.output_size = output_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x: Input tensor of shape (batch_size, seq_len, input_size)\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # check if previous hidden state is of the same size as the current batch size\n",
        "        if hidden[0].shape[1] != batch_size:\n",
        "            hidden = self.init_hidden(hidden[0].shape[1])\n",
        "\n",
        "\n",
        "        lstm_out, hidden = self.lstm(x, hidden) # lstm_out: tensor of shape (batch_size, seq_len, hidden_size)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        out = out.view(batch_size, -1)  # reshape to be batch_size first\n",
        "\n",
        "        # out = out[:, -1]    # get the last output for the sequence\n",
        "        out = out.mean(1) # we do not accent on the sequence but on semantics, so mean the vector!\n",
        "        return out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (\n",
        "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "        )\n",
        "        return hidden\n",
        "\n",
        "\n",
        "\n",
        "seq_len = 200  # Sequence length (max number of words in a tweet)\n",
        "input_size = 300  # Assuming input size is 300 (embedding size)\n",
        "hidden_dim = 200  # Number of hidden units in LSTM layer\n",
        "output_size = 1  # Output size for binary classification\n",
        "\n",
        "lstm_model = LSTMClassifier(\n",
        "    input_size=input_size,\n",
        "    hidden_dim=hidden_dim,\n",
        "    seq_len=seq_len,\n",
        "    output_size=output_size,\n",
        ")\n",
        "lstm_model.to(device)\n",
        "print(lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTp435fWxsq7"
      },
      "source": [
        "### Obtain tensors for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOjKyQdnuyij",
        "outputId": "f90375f1-7347-4fe7-aea7-bbdee33dff10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4301, 200, 300]),\n",
              " torch.Size([4301]),\n",
              " torch.Size([2119, 200, 300]),\n",
              " torch.Size([2119]))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# in_data = torch.tensor(X_train).float() # converting list to tensor can be extremely slow\n",
        "in_data = torch.tensor(\n",
        "    np.array(X_train)\n",
        ").float()  # converting list to numpy array and then to tensor is much faster\n",
        "targets = torch.tensor(np.array(y_train)).float()\n",
        "\n",
        "in_data_test = torch.tensor(\n",
        "    np.array(X_test)\n",
        ").float()  # converting list to numpy array and then to tensor is much faster\n",
        "targets_test = torch.tensor(np.array(y_test)).float()\n",
        "\n",
        "in_data.shape, targets.shape, in_data_test.shape, targets_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XWIjW_8xsq8"
      },
      "source": [
        "### Define DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IPQGyLYK0vqx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "batch_size = 256  # Batch size for training\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(in_data, targets)  # Create TensorDataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(in_data_test, targets_test)  # Create TensorDataset\n",
        "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps9WPbdGB5d4",
        "outputId": "dac72012-400c-44c5-e301-713843c71268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep  6 17:18:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W /  70W |    859MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FocB3ikpCAUC"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRtznF51xsq8",
        "outputId": "3ed9a2fa-80a7-4b10-c0a3-8dfd046656cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [07:25<00:00,  2.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 150\n",
        "counter = 0\n",
        "print_every = 10\n",
        "\n",
        "# clip  -  A threshold value that limits the magnitude of gradients.\n",
        "# If the gradient norm (the Euclidean norm or L2 norm) of all the model\n",
        "# parameters exceeds this value, the gradients are scaled down so that\n",
        "# the norm matches the specified maximum value (clip)\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "results = {\"loss\":[]}\n",
        "\n",
        "lstm_model.train()  # set lstm_model to train mode\n",
        "for i in tqdm(range(epochs)):\n",
        "    h = lstm_model.init_hidden(batch_size)  # initialize hidden state\n",
        "    # print(f'Epoch {i+1}/{epochs}', end= \"\\r\")\n",
        "\n",
        "    for inputs, targs in train_loader: # iterate through training data\n",
        "        if inputs.shape[0] != batch_size:\n",
        "            msg = f\"Batch size {inputs.shape[0]} does not match {batch_size}\"\n",
        "            # print(msg)\n",
        "            os.system(msg)\n",
        "            break\n",
        "\n",
        "        counter += 1\n",
        "        h = tuple([e.data for e in h])  # detach hidden state from history\n",
        "        inputs, targs = inputs.to(device), targs.to(device)\n",
        "        lstm_model.zero_grad()\n",
        "        output, h = lstm_model(inputs, h)\n",
        "        loss = criterion(output.squeeze(), targs.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(lstm_model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if counter % print_every == 0:\n",
        "            val_h = lstm_model.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            lstm_model.eval()\n",
        "            for inp, lab in val_loader:\n",
        "                if inp.shape[0] != batch_size:\n",
        "                    msg = f\"Batch size {inp.shape[0]} does not match {batch_size}\"\n",
        "                    # print(msg)\n",
        "                    os.system(msg)\n",
        "                    break\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                out, val_h = lstm_model(inp, val_h)\n",
        "                val_loss = criterion(out.squeeze(), lab.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            lstm_model.train()\n",
        "            # print(\n",
        "            #     \"Epoch: {}/{}...\".format(i + 1, epochs),\n",
        "            #     \"Step: {}...\".format(counter),\n",
        "            #     \"Loss: {:.6f}...\".format(loss.item()),\n",
        "            #     \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\n",
        "            #     end=\"\\r\"\n",
        "            # )\n",
        "\n",
        "            if np.mean(val_losses) <= valid_loss_min:\n",
        "                torch.save(lstm_model.state_dict(), \"./state_dict.pt\")\n",
        "                # print(\n",
        "                #     \"Validation loss decreased ({:.6f} --> {:.6f}).  Saving lstm_model ...\".format(\n",
        "                #         valid_loss_min, np.mean(val_losses)\n",
        "                #     )\n",
        "                # )\n",
        "                valid_loss_min = np.mean(val_losses)\n",
        "            results[\"loss\"].append(np.mean(val_losses))\n",
        "\n",
        "msg = \"Training complete!\"\n",
        "print(msg)\n",
        "os.system(f\"Say {msg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jnVSP9yPFNmB",
        "outputId": "be6c42c1-1569-438c-e0df-dd305aae8797"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"fcd41fc0-8b82-4ee4-8a33-47785b8962a2\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fcd41fc0-8b82-4ee4-8a33-47785b8962a2\")) {                    Plotly.newPlot(                        \"fcd41fc0-8b82-4ee4-8a33-47785b8962a2\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239],\"xaxis\":\"x\",\"y\":[0.6893374100327492,0.6854095011949539,0.6766891479492188,0.6574297100305557,0.6221023127436638,0.5680237114429474,0.43838203325867653,0.5807160884141922,0.40624962002038956,0.3298976942896843,0.3555024564266205,0.3086740616708994,0.29818934574723244,0.2924889251589775,0.28437529876828194,0.28300132043659687,0.2820903230458498,0.2741699069738388,0.30804454535245895,0.3073488026857376,0.33544179424643517,0.3618093952536583,0.27056376449763775,0.4315664768218994,0.33183370903134346,0.3935553804039955,0.2935945689678192,0.32076310366392136,0.2862863074988127,0.31786372885107994,0.28817217238247395,0.2888143416494131,0.29154555685818195,0.2755964882671833,0.32489271834492683,0.3289274126291275,0.2980531305074692,0.27575566060841084,0.3078972287476063,0.27884331345558167,0.2804993949830532,0.3087718281894922,0.2610345743596554,0.254036296159029,0.24987329170107841,0.2575973756611347,0.2501206025481224,0.24870608747005463,0.34008399210870266,0.28052299842238426,0.29103864170610905,0.26660318300127983,0.25775396078824997,0.26796762458980083,0.24820187874138355,0.24261068366467953,0.23688635230064392,0.2648483533412218,0.23189294151961803,0.23523009568452835,0.2414512149989605,0.2340013850480318,0.2613379266113043,0.2360887136310339,0.267580583691597,0.2579005118459463,0.25800311379134655,0.27405637316405773,0.3088350147008896,0.2885458767414093,0.28094189055263996,0.2625838555395603,0.25421006605029106,0.2677039224654436,0.2583661116659641,0.25802467577159405,0.2463811505585909,0.2380650546401739,0.26254414953291416,0.23261643759906292,0.23070592805743217,0.2301679663360119,0.2326796017587185,0.23549886606633663,0.24209866859018803,0.23563695326447487,0.22499398700892925,0.23679520562291145,0.2432509046047926,0.23634319379925728,0.25471227802336216,0.24350453354418278,0.24063493311405182,0.22679708898067474,0.2380134668201208,0.24596566520631313,0.23477447777986526,0.27748680859804153,0.22862368822097778,0.2219490483403206,0.24858336336910725,0.22097504138946533,0.23597568273544312,0.23208905942738056,0.24089939892292023,0.231281453743577,0.22105052880942822,0.23194032907485962,0.24022613652050495,0.26791672967374325,0.23285239562392235,0.2404011320322752,0.22162608616054058,0.22753883711993694,0.2301667220890522,0.22278966195881367,0.22829264216125011,0.21630256809294224,0.23042128793895245,0.22455172426998615,0.22133407555520535,0.22447468899190426,0.22686583548784256,0.21444371342658997,0.21586676873266697,0.2161448337137699,0.23390730284154415,0.23163495399057865,0.21699084155261517,0.2225997056812048,0.24445361271500587,0.2323884516954422,0.21883229166269302,0.22231313399970531,0.21073578111827374,0.21239891089498997,0.20335641130805016,0.21267699636518955,0.23313773423433304,0.20687631890177727,0.21867294050753117,0.20941675826907158,0.21530246548354626,0.20479289442300797,0.21790750324726105,0.21236923336982727,0.21435479447245598,0.2080576755106449,0.22267692349851131,0.22559244744479656,0.21667231433093548,0.21164500899612904,0.20616166852414608,0.2393995262682438,0.20556254126131535,0.21126325614750385,0.21239105239510536,0.1963984202593565,0.21745523065328598,0.2088646087795496,0.1971882712095976,0.21955706737935543,0.1952294185757637,0.1987138632684946,0.2028188221156597,0.20551291480660439,0.19676415249705315,0.1970545742660761,0.21239147149026394,0.19219540804624557,0.19622625596821308,0.19364644959568977,0.19187098741531372,0.21203118190169334,0.20172095485031605,0.1929480917751789,0.20619146525859833,0.19262662716209888,0.19470598176121712,0.19737562350928783,0.19977645203471184,0.18746730871498585,0.19763694889843464,0.2218791153281927,0.18637235648930073,0.18972894921898842,0.18769649043679237,0.2104043886065483,0.18300170823931694,0.2275467049330473,0.18201638758182526,0.20052378997206688,0.21638728491961956,0.18445360101759434,0.19118832051753998,0.194776251912117,0.19515291415154934,0.2018241249024868,0.22303129080682993,0.17770727910101414,0.190732903778553,0.17902755551040173,0.19395345449447632,0.18258656933903694,0.18916573747992516,0.18138146959245205,0.1863445956259966,0.18493091315031052,0.18546715937554836,0.1757016684859991,0.1877476666122675,0.18156677670776844,0.18270333483815193,0.19153832457959652,0.17896564863622189,0.19898377358913422,0.18152103014290333,0.19099356979131699,0.188664305023849,0.17747386917471886,0.19230405241250992,0.1775421816855669,0.17624272219836712,0.19170674495398998,0.18026790209114552,0.18500807508826256,0.17514531314373016,0.20443391986191273,0.16495967470109463,0.20623653382062912,0.17162050120532513,0.20313655957579613,0.16795783303678036,0.1772863920778036,0.17069477029144764,0.18023260403424501,0.19509195908904076,0.165492232888937,0.1711478866636753,0.20053853653371334],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"loss\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss (BCE with logits)\"},\"height\":500,\"font\":{\"size\":10}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fcd41fc0-8b82-4ee4-8a33-47785b8962a2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(\n",
        "    results[\"loss\"],\n",
        "    title=\"Loss (BCE with logits)\",\n",
        "    height=500,\n",
        ")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"epochs\",\n",
        "    yaxis_title=\"loss\",\n",
        "    font=dict(size=10),\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ByiX9AT0vqy"
      },
      "source": [
        "#### Inference. Make predictions on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VWsaiEZ-0vqy",
        "outputId": "99015624-fbb6-49be-abbc-b3dad9e55204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.953     0.917     0.935      1004\n",
            "         1.0      0.928     0.960     0.944      1115\n",
            "\n",
            "    accuracy                          0.940      2119\n",
            "   macro avg      0.941     0.938     0.939      2119\n",
            "weighted avg      0.940     0.940     0.940      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lstm_model.load_state_dict(torch.load('./state_dict.pt'))\n",
        "h = lstm_model.init_hidden(in_data_test.shape[0])\n",
        "lstm_model.eval()\n",
        "with torch.no_grad():\n",
        "    h = tuple([each.data for each in h])\n",
        "    in_data_test, targets_test = in_data_test.to(device), targets_test.to(device)\n",
        "    prediction,h = lstm_model(in_data_test,h)\n",
        "    prediction = (prediction.reshape(-1) > 0.5).cpu()\n",
        "    targets_test = targets_test.cpu()\n",
        "\n",
        "print(classification_report(targets_test, prediction, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD_JjujVby7p"
      },
      "source": [
        "Takeaways:\n",
        "1. In this particular task traditional approach of getting aggregated embedding of a tweet using w2v, tf-idf or CountingVectorizer perform quite well with similar to LSTM model results.  \n",
        "\n",
        "1. We can actually load pre-trained word embeddings such as GloVe or fastText which can increase the model’s accuracy and decrease training time."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}