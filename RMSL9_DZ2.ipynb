{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание по теме «Коллаборативная фильтрация»\n",
    "Пакет SURPRISE:\n",
    "\n",
    "используйте данные MovieLens 1M,\n",
    "можно использовать любые модели из пакета,\n",
    "получите RMSE на тестовом сете 0,87 и ниже.\n",
    "\n",
    "* Загружаем данные и собираем датасет(фильм-рейтинг)\n",
    "* Используем средства SURPRISE для перевода pandas датафрейма в нужный формат\n",
    "* Отбираем алгоритм/алгоритмы из SURPRISE, которые будем обучать\n",
    "* В процессе обучения выполняем проверку на 5 фолдах, оцениваем RMSE\n",
    "* Отбираем лучший алгоритм, при необходимости тьюним его\n",
    "https://surpriselib.com/\n",
    "\n",
    "Алгоритмы https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Загрузка данных и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\users\\asus\\jupiter-neto\\.venv\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\asus\\jupiter-neto\\.venv\\lib\\site-packages (from scikit-surprise) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\jupiter-neto\\.venv\\lib\\site-packages (from scikit-surprise) (1.23.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\jupiter-neto\\.venv\\lib\\site-packages (from scikit-surprise) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from surprise import Dataset, Trainset\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.similarities import cosine, msd, pearson, pearson_baseline\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase \n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans,\\\n",
    "KNNWithZScore, KNNBaseline\n",
    "from surprise.model_selection.search import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection.split import KFold\n",
    "from surprise.model_selection.validation import cross_validate\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Пользовательские функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset() -> Dataset:\n",
    "  \"\"\"\n",
    "  Prepare dataset for Surprise\n",
    "  \"\"\"\n",
    "  # load dataset\n",
    "  !wget  \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"  --no-check-certificate\n",
    "  # unzip data from zip\n",
    "  with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "  # read tables\n",
    "  movies = pd.read_csv('data\\\\ml-latest-small\\\\movies.csv')\n",
    "  ratings = pd.read_csv('data\\\\ml-latest-small\\\\ratings.csv')\n",
    "  ratings.drop(columns=['timestamp'], inplace=True)\n",
    "  # join tables\n",
    "  df = ratings.join(movies.set_index('movieId'), on='movieId', how='left')\n",
    "  dataset = pd.DataFrame({\n",
    "    'uid': df.userId,\n",
    "    'iid': df.title,\n",
    "    'rating': df.rating\n",
    "})\n",
    "  min = dataset.rating.min()\n",
    "  max = dataset.rating.max()\n",
    "  reader = Reader(rating_scale=(min, max)) \n",
    "  data = Dataset.load_from_df(dataset, reader)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algo(algo_name) -> AlgoBase():\n",
    "  \"\"\"\n",
    "  Make a dictionary with surprise models\n",
    "  Args:\n",
    "    algo_name:str - a name of surprise model\n",
    "  Return:\n",
    "    algos[algo_name]: AlgoBase - choosed model \n",
    "  \"\"\"\n",
    "  algos = dict()\n",
    "  algos['BaselineOnly'] = BaselineOnly()\n",
    "  algos['KNNWithMeans'] = KNNWithMeans()\n",
    "  algos['KNNWithZScore'] = KNNWithZScore()\n",
    "  algos['KNNBaseline'] = KNNBaseline()\n",
    "  return algos[algo_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(data: Dataset, split_ratio: float, random_seed: int) -> tuple[Trainset, Trainset, Trainset]:\n",
    "  \"\"\"Make datasets for fit, predict, cross_validate model\n",
    "  Args:\n",
    "    data: Dataset - whole dataset\n",
    "  Return:\n",
    "    trainset: Trainset,\n",
    "    testset: Trainset\n",
    "    traintestfull: Trainset\n",
    "  \"\"\"\n",
    "  trainset, testset = train_test_split(data, test_size=split_ratio, random_state=random_seed)\n",
    "  traintestfull = data.build_full_trainset()\n",
    "  return  trainset, testset, traintestfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( trainset: Trainset, testest: Trainset, algo_name: str) -> np.float64:\n",
    "  \"\"\"\n",
    "  Get algoritm by its name,\n",
    "  fit model, predict on test dataset\n",
    "  & return rmse\n",
    "  Will be used for primary algoritm's selecton\n",
    "  Args:\n",
    "    trainset: Trainset - train dataset\n",
    "    algo_name: str\n",
    "  Return: rmse: np.float64\n",
    "  \"\"\"\n",
    "  # get algoritm\n",
    "  algo = get_algo(algo_name)\n",
    "  # fit algoritm\n",
    "  algo.fit(trainset)\n",
    "  predictions = algo.test(testset)\n",
    "  return accuracy.rmse(predictions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(data, algo_name):\n",
    "  results = dict()\n",
    "  algo = get_algo(algo_name)\n",
    "  results = cross_validate(algo=algo, data=data, measures=['RMSE'], cv=5, return_train_measures=True)\n",
    "  kf = KFold(n_splits=5)\n",
    "  acc = []\n",
    "  for trainset, testset in kf.split(data):\n",
    "\n",
    "      # train and test algorithm.\n",
    "      algo.fit(trainset)\n",
    "      predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "      acc.append(accuracy.rmse(predictions, verbose=True))\n",
    "  return results['test_rmse'].mean(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-07-07 13:12:44--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "WARNING: cannot verify files.grouplens.org's certificate, issued by 'CN=R3,O=Let\\'s Encrypt,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: 'ml-latest-small.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5%  143K 6s\n",
      "    50K .......... .......... .......... .......... .......... 10%  296K 4s\n",
      "   100K .......... .......... .......... .......... .......... 15% 5.10M 3s\n",
      "   150K .......... .......... .......... .......... .......... 20%  313K 3s\n",
      "   200K .......... .......... .......... .......... .......... 26% 2.95M 2s\n",
      "   250K .......... .......... .......... .......... .......... 31% 24.8M 2s\n",
      "   300K .......... .......... .......... .......... .......... 36% 14.2M 1s\n",
      "   350K .......... .......... .......... .......... .......... 41% 5.53M 1s\n",
      "   400K .......... .......... .......... .......... .......... 47%  334K 1s\n",
      "   450K .......... .......... .......... .......... .......... 52% 6.10M 1s\n",
      "   500K .......... .......... .......... .......... .......... 57% 6.45M 1s\n",
      "   550K .......... .......... .......... .......... .......... 62% 7.52M 1s\n",
      "   600K .......... .......... .......... .......... .......... 68% 6.13M 0s\n",
      "   650K .......... .......... .......... .......... .......... 73% 7.96M 0s\n",
      "   700K .......... .......... .......... .......... .......... 78% 8.11M 0s\n",
      "   750K .......... .......... .......... .......... .......... 83% 5.41M 0s\n",
      "   800K .......... .......... .......... .......... .......... 88%  425K 0s\n",
      "   850K .......... .......... .......... .......... .......... 94% 8.30M 0s\n",
      "   900K .......... .......... .......... .......... .......... 99% 7.98M 0s\n",
      "   950K .....                                                 100% 14.9M=1.0s\n",
      "\n",
      "2023-07-07 13:12:47 (911 KB/s) - 'ml-latest-small.zip' saved [978202/978202]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, trainsetfull = build_features(data, 0.15, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save list of raw & inner item's id's\n",
    "trainset_iids = list(trainset.all_items()) # It is moviesId\n",
    "iid_converter = lambda x: trainset.to_raw_iid(x)\n",
    "trainset_raw_iids = list(map(iid_converter, trainset_iids)) # it is movies titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\n",
    " 'BaselineOnly',\n",
    " 'KNNWithMeans',         \n",
    " 'KNNWithZScore',\n",
    " 'KNNBaseline',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8717\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8782\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8694\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8696\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8738\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8996\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9078\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8981\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8940\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8955\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9079\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8965\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8891\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8963\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8958\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8783\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8764\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8722\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8675\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8739\n"
     ]
    }
   ],
   "source": [
    "cv_results = dict()\n",
    "cv_5 = dict()\n",
    "results = dict()\n",
    "for algo in algos:\n",
    "  results[algo] = train_model(trainset, testset, algo)\n",
    "  cv_results[algo], cv_5[algo] =  validate_model(data, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BaselineOnly': 0.8737114003217862,\n",
       " 'KNNWithMeans': 0.8955378893124751,\n",
       " 'KNNWithZScore': 0.894175350623354,\n",
       " 'KNNBaseline': 0.874123767263706}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BaselineOnly': 0.8729676746099791,\n",
       " 'KNNWithMeans': 0.8972381676383165,\n",
       " 'KNNWithZScore': 0.896553334056852,\n",
       " 'KNNBaseline': 0.8748385951293189}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BaselineOnly': [0.8717052600991458,\n",
       "  0.8781714700898999,\n",
       "  0.8694439501324589,\n",
       "  0.8695839273199019,\n",
       "  0.8737733352714818],\n",
       " 'KNNWithMeans': [0.8996062986589268,\n",
       "  0.9078242950699351,\n",
       "  0.8980946844683133,\n",
       "  0.8940173688340429,\n",
       "  0.8955001153258797],\n",
       " 'KNNWithZScore': [0.9078839559939339,\n",
       "  0.896548969144564,\n",
       "  0.8891393349904706,\n",
       "  0.8962744468675109,\n",
       "  0.8957736612716851],\n",
       " 'KNNBaseline': [0.8782825675094662,\n",
       "  0.8763859530246967,\n",
       "  0.8722111110555015,\n",
       "  0.867523079263711,\n",
       "  0.8738614987283699]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация на отложенном датасете помогает выбрать наиболее перспективные для дальнейшего изучения алгоритмы. ВЫберем KNNBaseline.Выполним для этих алгоритмов кросс-валидацию с параметрами по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNNWithMeans': 0.8964511992710749,\n",
       " 'KNNBaseline': 0.8751849954725367,\n",
       " 'KNNWithZScore': 0.896420945106889}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNNWithMeans': [0.9065331672252935,\n",
       "  0.9013035508937861,\n",
       "  0.8927859633903186,\n",
       "  0.8920246477594777,\n",
       "  0.8963935644444989],\n",
       " 'KNNBaseline': [0.8774524064622571,\n",
       "  0.8768064833762967,\n",
       "  0.8752693714850209,\n",
       "  0.8755628135662583,\n",
       "  0.8720178246797206],\n",
       " 'KNNWithZScore': [0.89720809095683,\n",
       "  0.8938095377372172,\n",
       "  0.8971338392777446,\n",
       "  0.9001861910596451,\n",
       "  0.894175350623354]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие результаты показывает KNNBaseline, но эти результаты >0.87. Попробуем улучшить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.865561570360341\n",
      "{'k': 30, 'min_k': 5, 'verbose': True, 'name': 'pearson', 'user_based': True, 'n_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"k\": [30], \"min_k\": [5],\"verbose\": [True],   \"name\": [\"pearson\"],   \"user_based\": [True, False], 'n_epochs':[10, 20]}\n",
    "gs3 = GridSearchCV(KNNBaseline, param_grid, measures=[\"rmse\"], cv=5)\n",
    "\n",
    "gs3.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs3.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs3.best_params[\"rmse\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат достигнут!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
